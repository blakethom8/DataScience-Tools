# Standard Review of Dataset
  df = pd.read_csv('data')
  df.info()
  df.describe()
  df.head()

  # count unique values in a category
  df_categories = df['column'].value_counts()  

  ## grab object columns and put their names in a list and drop the columns from dataset
  object_columns = df.select_dtypes('object').columns.tolist() 
  df_numeric = df.drop(object_columns, acis=1)

  float_columns_df = df.select_dtypes(include='float64') # or just use this to select float64 column types


  ## Find null values then drop null values
  null_by_column = df.isnull().sum()
  df_no_na = df.dropna(axis=0)

  ## Sort Columns
  sorted_df = df.sort_values(by="column_name")

  ## Find the correlated values to a column salesprice and find the most correlated value
  corr = train.corr()[['SalePrice']].nlargest(columns = 'SalePrice', n = 2).index[1]

  ## Process for removing outliers based on Zscore
  import numpy as np
  import scipy.stats as stats
  cali_floats= cali.select_dtypes(include='float64')

  z_scores = cali_floats.apply(stats.zscore) # calculates Z-score per each column 
  outlier_detection = (z_scores > 3) | (z_scores < -3) # passes boolean mask across z_scores dataframe
  outlier_detection.sum() # Check the number of outliers per column
  cali_no_outliers = cali[~outlier_detection.any(axis=1)] ## use this to pass a filter to the original dataset based on the boolean values, outputs a dataframe
  cali_no_outliers.info()


# PCA Analysis
  from sklearn.decomposition import PCA
  from sklearn.cluster import KMeans, DBSCAN
  from sklearn.preprocessing import StandardScaler

  ## Scale the dataset approach 1
  df_scaled = (df - df.mean()) / df.std()

    ### Set the PCA object and configure it 
    pca = ''
    pca = PCA(n_components=3, random_state=42)
  
    ### Create PCA Components
    components = pca.fit_transform(df_scaled)

  ## Scale the dataset approach 2
  X = default.values
  scaler = StandardScaler()
  scaler.fit(X)
  X_scaled = scaler.transform(X)
  
    ### Using Approach 2
    pca_all = PCA(random_state=2020)
    pca_all.fit(X_scaled)
    X_pca_all = pca_all.transform(X_scaled)

    show = X_scaled[:5]  
    print(show)

    ### Create Elbow Plot
    cum = np.cumsum(pca_all.explained_variance_ratio_)
    plt.plot(cum)
    plt.xlabel('number of components')
    plt.ylabel('explained variance')
    plt.savefig('elbow_plot.png', dpi=100)

  ## Create a heatmap of feature weight
  features = list(default.columns)
  loadings = pca_3.components_
  loadings_df = pd.DataFrame(loadings.T, columns=['PC1', 'PC2', 'PC3'], index=features)
  loadings_df

  plt.figure(figsize=(10,6))
  sns.heatmap(loadings_df, annot=True, cmap='RdBu_r', center=0)
  plt.title('PCA Loadings Heatmap')
  plt.show()

# K Means
  kmeans = ''
  df = pd.read_csv('data/marketing_campaign.csv', sep = '\t')
  df_clustered = df.dropna()
  df_clustered['cluster'] = ''

  kmeans = KMeans(n_clusters=3, random_state=42).fit(components)
  df = pd.read_csv('data/marketing_campaign.csv', sep = '\t')
  df_clustered = df.dropna(subset = ['Income'])
  df_clustered['cluster'] = kmeans.labels_

# K Means DBSCAN
  import numpy as np
  from sklearn.datasets import make_blobs
  import matplotlib.pyplot as plt
  import pandas as pd
  import seaborn as sns
  from sklearn.cluster import DBSCAN
  from mpl_toolkits import mplot3d

    # Set DBScan object
    dbscan = '' #Don't Forget to set the random_state!!!
    dbscan = DBSCAN()

    # Prediction Labels
    predictions = ''
    dbscan = DBSCAN().fit(X)
    predictions = dbscan.labels_

    # Understand label predictions
    unique_labels = ''
    n_clusters_default = ''
    unique_labels = np.unique(predictions)
    n_clusters_default = 0

# Putting PCA and KMeans Together
  1) df_scaled = (df_clean_nona - df_clean_nona.mean())/df_clean_nona.std() 
  2) pca = ''
     pca = PCA(n_components=3, random_state=42)
  3) components = pca.fit_transform(df_scaled)
  4) df_['cluster'] = '' # add cluster column
  5) kmeans = KMeans(n_clusters=3, random_state=42).fit(components) 
  6) df_clustered['cluster'] = kmeans.labels_

# Linear Regressions
  from sklearn.linear_model import LinearRegression

  X = geyser[['waiting']] # assign features as a dataframe
  y = geyser['duration'] # assign values as a series

  linreg = LinearRegression().fit(X, y)   # create the model object and fit it to the data 
  geyser['prediction'] = linreg.predict(X) # assign the predicted values back to the dataframe 

  slope = round(float(linreg.coef_), 2)
  intercept = round(float(linreg.intercept_), 2)

  ## Plot Linear Regression line in Plotly Graph
    import plotly.graph_objects as go 
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=data['total_bill'], y=data['tip'], 
                            mode = "markers", name = "actual")
                 )
    fig.add_trace(go.Scatter(x=data['total_bill'], y = data['prediction'], 
                            mode="lines", name="predicted"))
    
    fig.update_layout(font_size=20)

  ## Use Plotly Express
    fig = px.scatter(data, x = "total_bill", y = "tip", trendline = "ols", 
                 trendline_color_override = "black")
    results = px.get_trendline_results(fig)
    results.px_fit_results.iloc[0].params

## Simple Linear Regression with MSE example
  X = ''
  y = ''
  first_degree_model = ''
  first_degree_mse = ''
  
  # YOUR CODE HERE
  X = auto[['horsepower']]
  y = auto['mpg']
  
  first_degree_model = LinearRegression().fit(X,y)
  first_degree_mse = mean_squared_error(auto['mpg'], first_degree_model.predict(auto[['horsepower']]))
  
  ## Quadratic Regression
  X = ''
  y = ''
  quadratic_model = ''
  quad_mse = ''
  
  X = auto[['horsepower', 'hp2']]
  y = auto['mpg']
  quadratic_model = LinearRegression().fit(X,y)
  quad_mse = mean_squared_error(y, quadratic_model.predict(X))


## Plotting Quadratic 
  # Generating predictions
  x_range = np.linspace(auto['horsepower'].min(), auto['horsepower'].max(), 100)
  X_test = pd.DataFrame({'horsepower': x_range, 'hp2': x_range**2})
  y_pred = quadratic_model.predict(X_test)
  
  # Plotting the actual data points
  fig = go.Figure()
  fig.add_trace(go.Scatter(x=auto['horsepower'], y=auto['mpg'], mode='markers', name='Actual Data Points'))
  
  # Plotting the quadratic regression curve
  fig.add_trace(go.Scatter(x=x_range, y=y_pred, mode='lines', name='Quadratic Regression Model'))
  
  fig.update_layout(title='Quadratic Regression Model',
                    xaxis_title='Horsepower',
                    yaxis_title='MPG')
  
  fig.show()

## Using a Transformer to create exponential columns
  pfeatures = PolynomialFeatures(degree=3, include_bias=False)
  cubic_features_df = pd.DataFrame(pfeatures.fit_transform(auto[['horsepower']]),
                      columns = pfeatures.get_feature_names_out())


## finding the MSEs over a range of Features
mses = []
X = auto[['horsepower']]
y = auto['mpg']

#for 1, 2, 3, ..., 10
for i in range(1, 11):
    pipeline = Pipeline([
        ('number_features', PolynomialFeatures(degree = i, include_bias = False)),
        ('mode', LinearRegression())
    
    ])
    pipeline.fit(X, y)
    pipeline_mse = mean_squared_error(y, pipeline.predict(X))
    mses.append(pipeline_mse)

#find the minimum index
  best_complexity = mses.index(min(mses)) + 1

### I really like this example of module 8. Here, we are taking a subset of data
### as our development set. Training the model on the dataset, then predicting the
### the dev set and looking at the Variance of the different degress

  ## Create the development set
    X = auto.loc[:,['horsepower']]
    y = auto['mpg']
    sample = auto.sample(10, random_state = 22)
    X_train = sample.loc[:, ['horsepower']]
    y_train = sample['mpg']
  
  ## Insert the predicted outcomes into columns of model predictions
    model_predictions = {f'degree_{i}': None for i in range(1, 11)}
    
    X = auto[['horsepower']]
    y = auto['mpg']
    for i in range(1, 11):
        pipe = Pipeline([('quad_features', PolynomialFeatures(degree = i, include_bias = False)), 
                          ('quad_model', LinearRegression())])
        pipe.fit(X_train, y_train)
        preds = pipe.predict(X)
        model_predictions[f'degree_{i}'] = preds
    #Results check 
      model_predictions['degree_1'][:10]
    #Then convert it to a dataframe here
      pred_df = pd.DataFrame.from_dict(model_predictions)
    #Subtract actuals from the predicted values
      error_df = pred_df.subtract(y, axis = 0)
    #Look at the STD and box plot to see the variance in predicted values
      mean = error_df.mean()
      std = error_df.std()
      px.box(error_df)


  ## Another example of finding the best model parameters and then plotting it
    train_mses_ = []
    test_mses_ = []
    for i in range(1, 21):
        pipe = Pipeline([('pfeat', PolynomialFeatures(degree = i, include_bias=False)), 
                        ('linreg', LinearRegression())])
        pipe.fit(X_train, y1_train)
        train_preds_ = pipe.predict(X_train)
        test_preds_ = pipe.predict(X_test)
        train_mses_.append(mean_squared_error(y1_train_, train_preds_))
        test_mses_.append(mean_squared_error(y1_test_, test_preds_))
    best_model_complexity_ = test_mses_.index(min(test_mses_)) + 1

  ## + Plotting the example above 
    print(f'The Complexity that minimized Test Error was: {test_mses.index(min(test_mses)) + 1}')
    plt.plot(range(1, 21), train_mses, '--o', label = 'training error')
    plt.plot(range(1, 21), test_mses, '--o', label = 'testing error')
    plt.xticks(range(1, 21), range(1, 21))
    plt.xlabel('Degree Complexity')
    plt.ylabel('Mean Squared Error')
    plt.legend();

#################################

  # Splitting a training set
    X_train, X_test, y1_train, y1_test = train_test_split(df[['x']], df['y1'], random_state = 32, test_size=.3)
    y2_train, y2_test, y3_train, y3_test = train_test_split(df['y2'], df['y3'], random_state = 22, test_size=.3)

  ## Return the best model based using a training set and test set

    def simple_cross_validation(X_train, y_train, X_test, y_test):
        best_pipe = None #placeholder for best model
        best_mse = np.inf #set best mse to infinity to begin
        for i in range(1, 21):
            pipe = Pipeline([('pfeat', PolynomialFeatures(degree = i, include_bias=False)), 
                        ('linreg', LinearRegression())])
            pipe.fit(X_train, y_train)
            test_preds = pipe.predict(X_test)
            test_mse = mean_squared_error(y_test, test_preds)
            if test_mse < best_mse:
                best_mse = test_mse
                best_pipe = pipe
        return best_pipe

    best_model = simple_cross_validation(X_train, y2_train, X_test, y2_test)
    best_model.get_params() #should be degree = 10



  #### USing a pipeline with multiple column transformations to find the best model paremeters
  features = ['CentralAir', 'HeatingQC', 'OverallQual', 'GrLivArea', 'KitchenQual', 'FullBath']
  train_mses_ = []
  test_mses_ = []
  #for degree in 1 - 5
  for i in range(1, 6):
      #create pipeline with PolynomialFeatures degree i
      poly_ordinal_ohe_ = make_column_transformer((PolynomialFeatures(degree = i), make_column_selector(dtype_include=np.number)),
                                             (OrdinalEncoder(categories = [['Po', 'Fa', 'TA', 'Gd', 'Ex']]), ['HeatingQC']),
                                                 (OneHotEncoder(drop = 'if_binary'), ['CentralAir']))
      pipe = Pipeline([('transformer', poly_ordinal_ohe_), ('linreg', LinearRegression())])
  
      pipe.fit(X_train[features], y_train)
      #fit on train
      p1 = pipe.predict(X_train[features])
      p2 = pipe.predict(X_test[features])
      #predict on train and test
      train_mses.append(mean_squared_error(y_train, p1))
      test_mses.append(mean_squared_error(y_test, p2))
  
  best_complexity_ = test_mses_.index(min(test_mses_)) + 1
  best_mse_ = min(test_mses_)


  
