# Standard Review of Dataset
  df = pd.read_csv('data')
  df.info()
  df.describe()
  df.head()

  # count unique values in a category
  df_categories = df['column'].value_counts()  

  ## grab object columns and put their names in a list and drop the columns from dataset
  object_columns = df.select_dtypes('object').columns.tolist() 
  df_numeric = df.drop(object_columns, acis=1)

  float_columns_df = df.select_dtypes(include='float64') # or just use this to select float64 column types


  ## Find null values then drop null values
  null_by_column = df.isnull().sum()
  df_no_na = df.dropna(axis=0)

  ## Sort Columns
  sorted_df = df.sort_values(by="column_name")

  ## Find the correlated values to a column salesprice and find the most correlated value
  corr = train.corr()[['SalePrice']].nlargest(columns = 'SalePrice', n = 2).index[1]

  ## Process for removing outliers based on Zscore
  import numpy as np
  import scipy.stats as stats
  cali_floats= cali.select_dtypes(include='float64')

  z_scores = cali_floats.apply(stats.zscore) # calculates Z-score per each column 
  outlier_detection = (z_scores > 3) | (z_scores < -3) # passes boolean mask across z_scores dataframe
  outlier_detection.sum() # Check the number of outliers per column
  cali_no_outliers = cali[~outlier_detection.any(axis=1)] ## use this to pass a filter to the original dataset based on the boolean values, outputs a dataframe
  cali_no_outliers.info()

  ##Nice side by side histogram chart
    fig, ax = plt.subplots(1, 2, figsize = (15, 4))
    ax[0].hist(insurance['charges'])
    ax[0].grid()
    ax[0].set_title('Original charges column')
    ax[1].hist(np.log1p(insurance['charges']))
    ax[1].grid()
    ax[1].set_title('Logarithm of charges');


# PCA Analysis
  from sklearn.decomposition import PCA
  from sklearn.cluster import KMeans, DBSCAN
  from sklearn.preprocessing import StandardScaler

  ## Scale the dataset approach 1
  df_scaled = (df - df.mean()) / df.std()

    ### Set the PCA object and configure it 
    pca = ''
    pca = PCA(n_components=3, random_state=42)
  
    ### Create PCA Components
    components = pca.fit_transform(df_scaled)

  ## Scale the dataset approach 2
  X = default.values
  scaler = StandardScaler()
  scaler.fit(X)
  X_scaled = scaler.transform(X)
  
    ### Using Approach 2
    pca_all = PCA(random_state=2020)
    pca_all.fit(X_scaled)
    X_pca_all = pca_all.transform(X_scaled)

    show = X_scaled[:5]  
    print(show)

    ### Create Elbow Plot
    cum = np.cumsum(pca_all.explained_variance_ratio_)
    plt.plot(cum)
    plt.xlabel('number of components')
    plt.ylabel('explained variance')
    plt.savefig('elbow_plot.png', dpi=100)

  ## Create a heatmap of feature weight
  features = list(default.columns)
  loadings = pca_3.components_
  loadings_df = pd.DataFrame(loadings.T, columns=['PC1', 'PC2', 'PC3'], index=features)
  loadings_df

  plt.figure(figsize=(10,6))
  sns.heatmap(loadings_df, annot=True, cmap='RdBu_r', center=0)
  plt.title('PCA Loadings Heatmap')
  plt.show()

# K Means
  kmeans = ''
  df = pd.read_csv('data/marketing_campaign.csv', sep = '\t')
  df_clustered = df.dropna()
  df_clustered['cluster'] = ''

  kmeans = KMeans(n_clusters=3, random_state=42).fit(components)
  df = pd.read_csv('data/marketing_campaign.csv', sep = '\t')
  df_clustered = df.dropna(subset = ['Income'])
  df_clustered['cluster'] = kmeans.labels_

# K Means DBSCAN
  import numpy as np
  from sklearn.datasets import make_blobs
  import matplotlib.pyplot as plt
  import pandas as pd
  import seaborn as sns
  from sklearn.cluster import DBSCAN
  from mpl_toolkits import mplot3d

    # Set DBScan object
    dbscan = '' #Don't Forget to set the random_state!!!
    dbscan = DBSCAN()

    # Prediction Labels
    predictions = ''
    dbscan = DBSCAN().fit(X)
    predictions = dbscan.labels_

    # Understand label predictions
    unique_labels = ''
    n_clusters_default = ''
    unique_labels = np.unique(predictions)
    n_clusters_default = 0

# Putting PCA and KMeans Together
  1) df_scaled = (df_clean_nona - df_clean_nona.mean())/df_clean_nona.std() 
  2) pca = ''
     pca = PCA(n_components=3, random_state=42)
  3) components = pca.fit_transform(df_scaled)
  4) df_['cluster'] = '' # add cluster column
  5) kmeans = KMeans(n_clusters=3, random_state=42).fit(components) 
  6) df_clustered['cluster'] = kmeans.labels_

# Linear Regressions
  from sklearn.linear_model import LinearRegression

  X = geyser[['waiting']] # assign features as a dataframe
  y = geyser['duration'] # assign values as a series

  linreg = LinearRegression().fit(X, y)   # create the model object and fit it to the data 
  geyser['prediction'] = linreg.predict(X) # assign the predicted values back to the dataframe 

  slope = round(float(linreg.coef_), 2)
  intercept = round(float(linreg.intercept_), 2)

  ## Plot Linear Regression line in Plotly Graph
    import plotly.graph_objects as go 
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=data['total_bill'], y=data['tip'], 
                            mode = "markers", name = "actual")
                 )
    fig.add_trace(go.Scatter(x=data['total_bill'], y = data['prediction'], 
                            mode="lines", name="predicted"))
    
    fig.update_layout(font_size=20)

  ## Use Plotly Express
    fig = px.scatter(data, x = "total_bill", y = "tip", trendline = "ols", 
                 trendline_color_override = "black")
    results = px.get_trendline_results(fig)
    results.px_fit_results.iloc[0].params

## Simple Linear Regression with MSE example
  X = ''
  y = ''
  first_degree_model = ''
  first_degree_mse = ''
  
  # YOUR CODE HERE
  X = auto[['horsepower']]
  y = auto['mpg']
  
  first_degree_model = LinearRegression().fit(X,y)
  first_degree_mse = mean_squared_error(auto['mpg'], first_degree_model.predict(auto[['horsepower']]))
  
  ## Quadratic Regression
  X = ''
  y = ''
  quadratic_model = ''
  quad_mse = ''
  
  X = auto[['horsepower', 'hp2']]
  y = auto['mpg']
  quadratic_model = LinearRegression().fit(X,y)
  quad_mse = mean_squared_error(y, quadratic_model.predict(X))


## Plotting Quadratic 
  # Generating predictions
  x_range = np.linspace(auto['horsepower'].min(), auto['horsepower'].max(), 100)
  X_test = pd.DataFrame({'horsepower': x_range, 'hp2': x_range**2})
  y_pred = quadratic_model.predict(X_test)
  
  # Plotting the actual data points
  fig = go.Figure()
  fig.add_trace(go.Scatter(x=auto['horsepower'], y=auto['mpg'], mode='markers', name='Actual Data Points'))
  
  # Plotting the quadratic regression curve
  fig.add_trace(go.Scatter(x=x_range, y=y_pred, mode='lines', name='Quadratic Regression Model'))
  
  fig.update_layout(title='Quadratic Regression Model',
                    xaxis_title='Horsepower',
                    yaxis_title='MPG')
  
  fig.show()

## Using a Transformer to create exponential columns
  pfeatures = PolynomialFeatures(degree=3, include_bias=False)
  cubic_features_df = pd.DataFrame(pfeatures.fit_transform(auto[['horsepower']]),
                      columns = pfeatures.get_feature_names_out())


## finding the MSEs over a range of Features
mses = []
X = auto[['horsepower']]
y = auto['mpg']

#for 1, 2, 3, ..., 10
for i in range(1, 11):
    pipeline = Pipeline([
        ('number_features', PolynomialFeatures(degree = i, include_bias = False)),
        ('mode', LinearRegression())
    
    ])
    pipeline.fit(X, y)
    pipeline_mse = mean_squared_error(y, pipeline.predict(X))
    mses.append(pipeline_mse)

#find the minimum index
  best_complexity = mses.index(min(mses)) + 1

### I really like this example of module 8. Here, we are taking a subset of data
### as our development set. Training the model on the dataset, then predicting the
### the dev set and looking at the Variance of the different degress

  ## Create the development set
    X = auto.loc[:,['horsepower']]
    y = auto['mpg']
    sample = auto.sample(10, random_state = 22)
    X_train = sample.loc[:, ['horsepower']]
    y_train = sample['mpg']
  
  ## Insert the predicted outcomes into columns of model predictions
    model_predictions = {f'degree_{i}': None for i in range(1, 11)}
    
    X = auto[['horsepower']]
    y = auto['mpg']
    for i in range(1, 11):
        pipe = Pipeline([('quad_features', PolynomialFeatures(degree = i, include_bias = False)), 
                          ('quad_model', LinearRegression())])
        pipe.fit(X_train, y_train)
        preds = pipe.predict(X)
        model_predictions[f'degree_{i}'] = preds
    #Results check 
      model_predictions['degree_1'][:10]
    #Then convert it to a dataframe here
      pred_df = pd.DataFrame.from_dict(model_predictions)
    #Subtract actuals from the predicted values
      error_df = pred_df.subtract(y, axis = 0)
    #Look at the STD and box plot to see the variance in predicted values
      mean = error_df.mean()
      std = error_df.std()
      px.box(error_df)


  ## Another example of finding the best model parameters and then plotting it
    train_mses_ = []
    test_mses_ = []
    for i in range(1, 21):
        pipe = Pipeline([('pfeat', PolynomialFeatures(degree = i, include_bias=False)), 
                        ('linreg', LinearRegression())])
        pipe.fit(X_train, y1_train)
        train_preds_ = pipe.predict(X_train)
        test_preds_ = pipe.predict(X_test)
        train_mses_.append(mean_squared_error(y1_train_, train_preds_))
        test_mses_.append(mean_squared_error(y1_test_, test_preds_))
    best_model_complexity_ = test_mses_.index(min(test_mses_)) + 1

  ## + Plotting the example above 
    print(f'The Complexity that minimized Test Error was: {test_mses.index(min(test_mses)) + 1}')
    plt.plot(range(1, 21), train_mses, '--o', label = 'training error')
    plt.plot(range(1, 21), test_mses, '--o', label = 'testing error')
    plt.xticks(range(1, 21), range(1, 21))
    plt.xlabel('Degree Complexity')
    plt.ylabel('Mean Squared Error')
    plt.legend();

#################################

  # Splitting a training set
    X_train, X_test, y1_train, y1_test = train_test_split(df[['x']], df['y1'], random_state = 32, test_size=.3)
    y2_train, y2_test, y3_train, y3_test = train_test_split(df['y2'], df['y3'], random_state = 22, test_size=.3)

  ## Return the best model based using a training set and test set

    def simple_cross_validation(X_train, y_train, X_test, y_test):
        best_pipe = None #placeholder for best model
        best_mse = np.inf #set best mse to infinity to begin
        for i in range(1, 21):
            pipe = Pipeline([('pfeat', PolynomialFeatures(degree = i, include_bias=False)), 
                        ('linreg', LinearRegression())])
            pipe.fit(X_train, y_train)
            test_preds = pipe.predict(X_test)
            test_mse = mean_squared_error(y_test, test_preds)
            if test_mse < best_mse:
                best_mse = test_mse
                best_pipe = pipe
        return best_pipe

    best_model = simple_cross_validation(X_train, y2_train, X_test, y2_test)
    best_model.get_params() #should be degree = 10



  #### USing a pipeline with multiple column transformations to find the best model paremeters
  features = ['CentralAir', 'HeatingQC', 'OverallQual', 'GrLivArea', 'KitchenQual', 'FullBath']
  train_mses_ = []
  test_mses_ = []
  #for degree in 1 - 5
  for i in range(1, 6):
      #create pipeline with PolynomialFeatures degree i
      poly_ordinal_ohe_ = make_column_transformer((PolynomialFeatures(degree = i), make_column_selector(dtype_include=np.number)),
                                             (OrdinalEncoder(categories = [['Po', 'Fa', 'TA', 'Gd', 'Ex']]), ['HeatingQC']),
                                                 (OneHotEncoder(drop = 'if_binary'), ['CentralAir']))
      pipe = Pipeline([('transformer', poly_ordinal_ohe_), ('linreg', LinearRegression())])
  
      pipe.fit(X_train[features], y_train)
      #fit on train
      p1 = pipe.predict(X_train[features])
      p2 = pipe.predict(X_test[features])
      #predict on train and test
      train_mses.append(mean_squared_error(y_train, p1))
      test_mses.append(mean_squared_error(y_test, p2))
  
  best_complexity_ = test_mses_.index(min(test_mses_)) + 1
  best_mse_ = min(test_mses_)


## Sequential Feature Selection
  poly3 = PolynomialFeatures(degree=3, include_bias=False)
  all_degree_3_combinations = poly3.fit_tranform(vehicle_data[['cylinders', 'weight', 'hp']_
  all_degree_3_combinations = pd.DataFrame(all_degree_3_combinations, columns = poly3.get_feature_names_out())

# need to create two list of numbers, so pass indices for Test and Dev set
  all_indices = range(0, len(vehicle_data))
  all indices = shuffle(all_indices)
  training_indices, dev_indices =  np.split(all_indices, [320])

  # pass argument 
  feature_select = SequentialFeatureSelector(
                      estimator = LinearRegression(), 
                      scoring = 'neg_mean_squared_error', 
                      cv=[[training_indices, dev_indices]],   #cv stands for cross-validation
                      n_features_to_select = 4 )

  # fit transform on our data and capture output
    best_four = pd.DataFrame(feature_Select.fit_transform(all_degree_3_combinations, 
        vehicle_data['mpg'], 
        columns = feature_select.get_feature_names_out())

  # Compare performance
    best_four_sfs_model = LinearRegression()
    best_four_sfs_model.fit(best_four_features.iloc[training_indices], vehicle_data.iloc[training_indices]['mpg'])

## Sequential Feature Example 2 - Insurance
  #split the dataset
  X_train, X_test, y_train, y_test = train_test_split(insurance.drop('charges', axis = 1), np.log1p(insurance.charges), 
                                                   random_state=42, test_size = 0.3)
  #create a dataframe of the features
    poly_features = PolynomialFeatures(degree = 3, include_bias=False)
    X_train_poly = poly_features.fit_transform(X_train[['age', 'bmi', 'children']])
    X_test_poly = poly_features.fit_transform(X_test[['age', 'bmi', 'children']])
    columns = poly_features.get_feature_names_out()
    train_df = pd.DataFrame(X_train_poly, columns=columns)
    test_df = pd.DataFrame(X_test_poly, columns = columns)

  #use Sequential Feature Selection and convert to DF
    selector = SequentialFeatureSelector(LinearRegression(), n_features_to_select=3)
    best_features = selector.fit_transform(train_df, y_train)
    best_features_df = pd.DataFrame(best_features, columns = selector.get_feature_names_out())

  #create a pipeline of the regression model
    pipe = Pipeline([('column_selector', selector),
                    ('linreg', LinearRegression())])
    pipe.fit(train_df, y_train)
    train_preds = pipe.predict(train_df)
    test_preds = pipe.predict(test_df)
    train_mse = mean_squared_error(y_train, train_preds)
    test_mse = mean_squared_error(y_test, test_preds)

#Ridge and LASSO Regularization are used to control the complexity
  #subset dataset
      X_train_ = train_df.drop('target_log', axis = 1)
      X_test_ = test_df.drop('target_log', axis = 1)
      y_train_ = train_df['target_log']
      y_test_ = test_df['target_log']
  #Ridge-ify  
    model_1 = Ridge().fit(X_train, y_train)
    model_1_coefs = model_1.coef_


#Good example of mapping the results on a dataset
  data = pd.read_csv('data/synthetic_9.4.csv')
  X, y = data[['x']], data['y']
  ols_pipe = Pipeline([('poly_features', PolynomialFeatures(degree = 5, include_bias= False)), 
                     ('linreg', LinearRegression())])
  ols_pipe.fit(X, y)
  ols_preds = ols_pipe.predict(X)

  ##Plot
    Xnp = X.to_numpy()
    plt.scatter(Xnp, y, label = 'data')
    plt.plot(Xnp, ols_preds, 'r--', label = 'ols predictions')
    plt.legend()
    plt.grid();

#Applying a Standard Scaler to the pipeline
  scaled_pipe = Pipeline([('scaler', StandardScaler()), ('ridge', Ridge())]).fit(X_train, y_train)
  train_preds = scaled_pipe.predict(X_train)
  test_preds = scaled_pipe.predict(X_test)
  train_mse = mean_squared_error(y_train, train_preds)
  test_mse = mean_squared_error(y_test, test_preds)

##Using GridSearch CV
  scaled_ridge_model = Pipeline([
    ('josh_transform', PolynomialFeatures(degree=3, include_bias = False)),
    ('scale', StandardScaler()),
    ('josh_regression', Ridge())
    )]
  parameters_to_try = { 'josh_regression_alpha': 10**np.linspace(-5, 4, 100)}

  from sklearn.model_selection import GridSearchCV
  model_finder = GridSearchCV(
    estimator = scaled_ridge_model,
    param_grid = parameters_to_try,
    scoring = 'neg_mean_squared_error'.
    cv = [[training_indices, dev_indices]]
    )

    model_finder.fit(vehicle_data[numeric_features], vehicle_data;"mpg"])
    best_model = model_finder.best_estimator 
    best_model.names_steps['josh_regression'].coef_ #see the coefficients
    model_finder.cv_results_ #when doing this, change parameters to try to reduce space 
        i.e. parameters_to_try = {'josh_regression_alpha': [0.001, 1, 1000]}

##Grid CV using sequential model selection
  selector_pipe = Pipeline([('selector', SequentialFeatureSelector(LinearRegression())),
                         ('model', LinearRegression())])

  param_dict = {'selector__n_features_to_select': [2, 3, 4, 5]}
  selector_grid = GridSearchCV(selector_pipe, param_grid=param_dict)
  selector_grid.fit(X_train, y_train)
  train_preds = selector_grid.predict(X_train)
  test_preds = selector_grid.predict(X_test)
  selector_train_mse = mean_squared_error(y_train, train_preds)
  selector_test_mse = mean_squared_error(y_test, test_preds)

  best_estimator = selector_grid.best_estimator_   #grab best estimator
  best_selector = best_estimator.named_steps['selector']  #extract the selector from pipeline
  best_model = selector_grid.best_estimator_.named_steps['model']  #extract the model from pipeline
  feature_names = X_train.columns[best_selector.get_support()]  #extract best features from selector, returns booleans if they were selected or not
  coefs = best_model.coef_    #coefficients from best model

  print(best_estimator)
  print(f'Features from best selector: {feature_names}.')
  print('Coefficient values: ')
  print('===================')
  pd.DataFrame([coefs.T], columns = feature_names, index = ['model'])

#Using Lasso as feature selection
  model_selector_pipe = Pipeline([('poly_features', PolynomialFeatures(degree = 3, include_bias = False)),
                                ('scaler', StandardScaler()),
                                ('selector', SelectFromModel(Lasso())),
                                ('linreg', LinearRegression())])
  model_selector_pipe.fit(auto_X_train, auto_y_train)
  selector_train_mse = mean_squared_error(auto_y_train, model_selector_pipe.predict(auto_X_train))
  selector_test_mse = mean_squared_error(auto_y_test, model_selector_pipe.predict(auto_X_test))


# Time Forecasting 
  pd.to_datetime(df['Date')
  df = df.set_index(pd.to_datetime(df['Date'])
  df.drop(columns = ['column1', 'column2'], inplace=True)
  df.rename(columns = {'originalcolumnname' : 'newcolumnname' }, inplace = True)

  df.plot()


#KNN Classifiers 

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, recall_score, precision_score
from sklearn.datasets import load_breast_cancer
from sklearn import set_config

set_config(display="diagram")

# Baseline Example - Student Loan
  X_train, X_test, y_train, y_test = train_test_split(df.drop('default', axis = 1), 
                                                      df['default'],
                                                     random_state=42)
  baseline = df['default'].value_counts(normalize = True)[0] #always check baseline accuracy

# Set up our column transformer and pipeline
  transformer = make_column_transformer((OneHotEncoder(drop = 'if_binary'), ['student']),
                                     remainder = StandardScaler())
  knn_pipe = Pipeline([('transform', transformer), ('knn', KNeighborsClassifier())])

# Set parameters for a search
  params = {'knn__n_neighbors': list(range(1, 22, 2))}

# GridSearch for best K parameters and model accuracy
  params = {'knn__n_neighbors': list(range(1, 22, 2))}
  knn_grid = GridSearchCV(knn_pipe, param_grid=params)
  knn_grid.fit(X_train, y_train)
  best_k = list(knn_grid.best_params_.values())[0]
  best_acc = knn_grid.score(X_test, y_test)
  
  print(best_acc)  #best accurace
  print(best_k)

# You can also change up how we want to weigh the different points
# You can also have your output share the probility it felt for each prediction
  base_pipe.fit(X_train, y_train)
  base_probs = base_pipe.predict_proba(X_test)

# And we can adjust the cutoff threshold for yes vs no. Here, we raise the threshold to 70% probability
  base_pipe = Pipeline([('transformer', transformer), ('knn', KNeighborsClassifier(n_neighbors=10))])
  base_pipe.fit(X_train, y_train)
  base_probs = base_pipe.predict_proba(X_test)
  strict_preds = np.where(base_probs[:, 0] > .7, 'No', 'Yes')
  strict_fn = 0
  for i, j in zip(strict_preds, y_test):
      if i == 'No':
          if j == 'Yes':
              strict_fn += 1

# Tumor Example

  X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis = 1), df.target, 
                                                      random_state = 42,
                                                     stratify = df.target)
## Always check the baseline for accuracy baseline
  y_test.value_counts(normalize = True)
  y_train.value_counts(normalize = True)

# set up our KNN pipeline
  knn_pipe = Pipeline([('scale', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors = 10))])
  knn_pipe.fit(X_train, y_train)

# You can pass different scoring methods to the from sci-kit learn to alter preferences
  min_fp_precision = precision_score(y_test, knn_pipe.predict(X_test), pos_label = 'malignant')
  min_fp_recall = recall_score(y_test, knn_pipe.predict(X_test), pos_label = 'malignant')
  min_fp_accuracy = accuracy_score(y_test, knn_pipe.predict(X_test))
  
  print(min_fp_precision)
  print(min_fp_recall)
  print(min_fp_accuracy)

# For tumors, we want the test to have the best recall so we limit our false negatives
# We can run a gridsearchCV to find the best nearest neighbors to reduce Recall
  target_map = {'malignant': 1, 'benign': 0} #we want the metric to be numerical

  y_train_numeric = y_train.map(target_map)
  y_test_numeric = y_test.map(target_map)
  recall_grid = GridSearchCV(knn_pipe, param_grid = {'knn__n_neighbors': range(1, 23, 2)},
                     scoring = 'recall')
  recall_grid.fit(X_train, y_train_numeric)
  best_score = recall_grid.score(X_test, y_test_numeric)
  print(f'The best recall score is: {best_score: .2f}')  

# Here is how we would check the TP, FN by hand
  recall_preds = recall_grid.predict(X_test)
  fn = 0
  tp = 0
  for i,j in zip(recall_preds, y_test_numeric):
      if i == 0 and j == 1:
          fn += 1
      if i == 1 and j == 1:
          tp += 1
  print(f'Recall by hand is: {tp/(tp + fn): .2f}')







  
    


    




  


  
